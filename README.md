# Spatio-Temporal Prediction Paper

## 2023

### KDD 2023

| Title | Authors | Abstract | Task | Method |
| --- | --- | --- | --- | --- |
| [Localised Adaptive Spatial-Temporal Graph Neural Network](https://doi.org/10.1145/3580305.3599418) | Wenying Duan, Xiaoxi He, Zimu Zhou, Lothar Thiele, Hong Rao | Spatial-temporal graph models are prevailing for abstracting and modelling spatial and temporal dependencies. In this work, we ask the following question: whether and to what extent can we localise spatial-temporal graph models? We limit our scope to adaptive spatial-temporal graph neural networks (ASTGNNs), the state-of-the-art model architecture. Our approach to localisation involves sparsifying the spatial graph adjacency matrices. To this end, we propose Adaptive Graph Sparsification (AGS), a graph sparsification algorithm which successfully enables the localisation of ASTGNNs to an extreme extent (fully localisation). We apply AGS to two distinct ASTGNN architectures and nine spatial-temporal datasets. Intriguingly, we observe that spatial graphs in ASTGNNs can be sparsified by over 99.5% without any decline in test accuracy. Furthermore, even when ASTGNNs are fully localised, becoming graph-less and purely temporal, we record no drop in accuracy for the majority of tested datasets, with only minor accuracy deterioration observed in the remaining datasets. However, when the partially or fully localised ASTGNNs are reinitialised and retrained on the same data, there is a considerable and consistent drop in accuracy. Based on these observations, we reckon that (i) in the tested data, the information provided by the spatial dependencies is primarily included in the information provided by the temporal dependencies and, thus, can be essentially ignored for inference; and (ii) although the spatial dependencies provide redundant information, it is vital for the effective training of ASTGNNs and thus cannot be ignored during training. Furthermore, the localisation of ASTGNNs holds the potential to reduce the heavy computation overhead required on large-scale spatial-temporal data and further enable the distributed deployment of ASTGNNs. | The paper addresses the task of localising spatial-temporal graph models and explores the impact of sparsifying the spatial graph adjacency matrices on adaptive spatial-temporal graph neural networks (ASTGNNs). | The proposed approach is Adaptive Graph Sparsification (AGS), a graph sparsification algorithm that enables the localisation of ASTGNNs. AGS successfully sparsifies the spatial graph adjacency matrices, resulting in extreme localisation. |
| [Frigate: Frugal Spatio-temporal Forecasting on Road Networks](https://doi.org/10.1145/3580305.3599357) | Mridul Gupta, Hariprasad Kodamana, Sayan Ranu | Modelling spatio-temporal processes on road networks is a task of growing importance. While significant progress has been made on developing spatio-temporal graph neural networks (Gnns), existing works are built upon three assumptions that are not practical on real-world road networks. First, they assume sensing on every node of a road network. In reality, due to budget-constraints or sensor failures, all locations (nodes) may not be equipped with sensors. Second, they assume that sensing history is available at all installed sensors. This is unrealistic as well due to sensor failures, loss of packets during communication, etc. Finally, there is an assumption of static road networks. Connectivity within networks change due to road closures, constructions of new roads, etc. In this work, we develop Frigate to address all these shortcomings. Frigate is powered by a spatio-temporal Gnn that integrates positional, topological, and temporal information into rich inductive node representations. The joint fusion of this diverse information is made feasible through a novel combination of gated Lipschitz embeddings with Lstms. We prove that the proposed Gnn architecture is provably more expressive than message-passing Gnns used in state-of-the-art algorithms. The higher expressivity of Frigate naturally translates to superior empirical performance conducted on real-world network-constrained traffic data. In addition, Frigate is robust to frugal sensor deployment, changes in road network connectivity, and temporal irregularity in sensing. | Spatio-temporal forecasting on road networks | Frigate is powered by a spatio-temporal Gnn that integrates positional, topological, and temporal information into rich inductive node representations. The joint fusion of this diverse information is made feasible through a novel combination of gated Lipschitz embeddings with LSTMs. |
| [Mitigating Action Hysteresis in Traffic Signal Control with Traffic Predictive Reinforcement Learning](https://doi.org/10.1145/3580305.3599528) | Xiao Han, Xiangyu Zhao, Liang Zhang, Wanyu Wang | Traffic signal control plays a pivotal role in the management of urban traffic flow. With the rapid advancement of reinforcement learning, the development of signal control methods has seen a significant boost. However, a major challenge in implementing these methods is ensuring that signal lights do not change abruptly, as this can lead to traffic accidents. To mitigate this risk, a time-delay is introduced in the implementation of control actions, but usually has a negative impact on the overall efficacy of the control policy. To address this challenge, this paper presents a novel Traffic Signal Control Framework (PRLight), which leverages an On-policy Traffic Control Model (OTCM) and an Online Traffic Prediction Model (OTPM) to achieve efficient and real-time control of traffic signals. The framework collects multi-source traffic information from a local-view graph in real-time and employs a novel fast attention mechanism to extract relevant traffic features. To be specific, OTCM utilizes the predicted traffic state as input, eliminating the need for communication with other agents and maximizing computational efficiency while ensuring that the most relevant information is used for signal control. The proposed framework was evaluated on both simulated and real-world road networks and compared to various state-of-the-art methods, demonstrating its effectiveness in preventing traffic congestion and accidents. | Traffic signal control | Traffic Signal Control Framework (PRLight) leveraging On-policy Traffic Control Model (OTCM) and Online Traffic Prediction Model (OTPM) |
| [Graph Neural Processes for Spatio-Temporal Extrapolation](https://doi.org/10.1145/3580305.3599372) | Junfeng Hu, Yuxuan Liang, Zhencheng Fan, Hongyang Chen, Yu Zheng, Roger Zimmermann | We study the task of spatio-temporal extrapolation that generates data at target locations from surrounding contexts in a graph. This task is crucial as sensors that collect data are sparsely deployed, resulting in a lack of fine-grained information due to high deployment and maintenance costs. Existing methods either use learning-based models like Neural Networks or statistical approaches like Gaussian Processes for this task. However, the former lacks uncertainty estimates and the latter fails to capture complex spatial and temporal correlations effectively. To address these issues, we propose Spatio-Temporal Graph Neural Processes (STGNP), a neural latent variable model which commands these capabilities simultaneously. Specifically, we first learn deterministic spatio-temporal representations by stacking layers of causal convolutions and cross-set graph neural networks. Then, we learn latent variables for target locations through vertical latent state transitions along layers and obtain extrapolations. Importantly during the transitions, we propose Graph Bayesian Aggregation (GBA), a Bayesian graph aggregator that aggregates contexts considering uncertainties in context data and graph structure. Extensive experiments show that STGNP has desirable properties such as uncertainty estimates and strong learning capabilities, and achieves state-of-the-art results by a clear margin. | Spatio-Temporal Extrapolation | Spatio-Temporal Graph Neural Processes (STGNP) |
| [ST-iFGSM: Enhancing Robustness of Human Mobility Signature Identification Model via Spatial-Temporal Iterative FGSM](https://doi.org/10.1145/3580305.3599513) | Mingzhi Hu, Xin Zhang, Yanhua Li, Xun Zhou, Jun Luo | The Human Mobility Signature Identification (HuMID) problem aims at determining whether the incoming trajectories were generated by a claimed agent from the historical movement trajectories of a set of individual human agents such as pedestrians and taxi drivers. The HuMID problem is significant, and its solutions have a wide range of real-world applications, such as criminal identification for police departments, risk assessment for auto insurance providers, driver verification in ride-sharing services, and so on. Though Deep neural networks (DNN) based HuMID models on spatial-temporal mobility fingerprint similarity demonstrate remarkable performance in effectively identifying human agents' mobility signatures, it is vulnerable to adversarial attacks as other DNN-based models. Therefore, in this paper, we propose a Spatial-Temporal iterative Fast Gradient Sign Method with L0regularization - ST-iFGSM - to detect the vulnerability and enhance the robustness of HuMID models. Extensive experiments with real-world taxi trajectory data demonstrate the efficiency and effectiveness of our ST-iFGSM algorithm. We tested our method on both the ST-SiameseNet and an LSTM-based HuMID classification model. It shows that ST-iFGSM can generate successful attacks to fool the HuMID models with only a few steps of attack in a small portion of the trajectories. The generated attacks can be used as augmented data to update and improve the HuMID model accuracy significantly from 47.36% to 76.18% on testing samples after the attack(86.25% on the original testing samples). | Enhancing the robustness of Human Mobility Signature Identification (HuMID) models | Spatial-Temporal iterative Fast Gradient Sign Method with L0 regularization (ST-iFGSM) |
| [Transferable Graph Structure Learning for Graph-based Traffic Forecasting Across Cities](https://doi.org/10.1145/3580305.3599529) | Yilun Jin, Kai Chen, Qiang Yang | Graph-based deep learning models are powerful in modeling spatio-temporal graphs for traffic forecasting. In practice, accurate forecasting models rely on sufficient traffic data, which may not be accessible in real-world applications. To address this problem, transfer learning methods are designed to transfer knowledge from the source graph with abundant data to the target graph with limited data. However, existing methods adopt pre-defined graph structures for knowledge extraction and transfer, which may be noisy or biased and negatively impact the performance of knowledge transfer. To address the problem, we propose TransGTR, a transferable structure learning framework for traffic forecasting that jointly learns and transfers the graph structures and forecasting models across cities. TransGTR consists of a node feature network, a structure generator, and a forecasting model. We train the node feature network with knowledge distillation to extract city-agnostic node features, such that the structure generator, taking the node features as inputs, can be transferred across both cities. Furthermore, we train the structure generator via a temporal decoupled regularization, such that the spatial features learned with the generated graphs share similar distributions across cities and thus facilitate knowledge transfer for the forecasting model. We evaluate TransGTR on real-world traffic speed datasets, where under a fair comparison, TransGTR outperforms state-of-the-art baselines by up to 5.4%. | Traffic forecasting | TransGTR (Transferable Graph Structure Learning) |
| [Optimizing Traffic Control with Model-Based Learning: A Pessimistic Approach to Data-Efficient Policy Inference](https://doi.org/10.1145/3580305.3599459) | Mayuresh Kunjir, Sanjay Chawla, Siddarth Chandrasekar, Devika Jay, Balaraman Ravindran | Traffic signal control is an important problem in urban mobility with a significant potential for economic and environmental impact. While there is a growing interest in Reinforcement Learning (RL) for traffic signal control, the work so far has focussed on learning through simulations which could lead to inaccuracies due to simplifying assumptions. Instead, real experience data on traffic is available and could be exploited at minimal costs. Recent progress in offline or batch RL has enabled just that. Model-based offline RL methods, in particular, have been shown to generalize from the experience data much better than others.We build a model-based learning framework that infers a Markov Decision Process (MDP) from a dataset collected using a cyclic traffic signal control policy that is both commonplace and easy to gather. The MDP is built with pessimistic costs to manage out-of-distribution scenarios using an adaptive shaping of rewards which is shown to provide better regularization compared to the prior related work in addition to being PAC-optimal. Our model is evaluated on a complex signalized roundabout and a large multi-intersection environment, demonstrating that highly performant traffic control policies can be built in a data-efficient manner. | Traffic signal control optimization | Model-based learning framework |
| [MM-DAG: Multi-task DAG Learning for Multi-modal Data - with Application for Traffic Congestion Analysis](https://doi.org/10.1145/3580305.3599436) | Tian Lan, Ziyue Li, Zhishuai Li, Lei Bai, Man Li, Fugee Tsung, Wolfgang Ketter, Rui Zhao, Chen Zhang | This paper proposes to learn Multi-task, Multi-modal Direct Acyclic Graphs (MM-DAGs), which are commonly observed in complex systems, e.g., traffic, manufacturing, and weather systems, whose variables are multi-modal with scalars, vectors, and functions. This paper takes the traffic congestion analysis as a concrete case, where a traffic intersection is usually regarded as a DAG. In a road network of multiple intersections, different intersections can only have someoverlapping and distinct variables observed. For example, a signalized intersection has traffic light-related variables, whereas unsignalized ones do not. This encourages the multi-task design: with each DAG as a task, the MM-DAG tries to learn the multiple DAGs jointly so that their consensus and consistency are maximized. To this end, we innovatively propose a multi-modal regression for linear causal relationship description of different variables. Then we develop a novel Causality Difference (CD) measure and its differentiable approximator. Compared with existing SOTA measures, CD can penalize the causal structural difference among DAGs with distinct nodes and can better consider the uncertainty of causal orders. We rigidly prove our design's topological interpretation and consistency properties. We conduct thorough simulations and one case study to show the effectiveness of our MM-DAG. The code is available under https://github.com/Lantian72/MM-DAG. | Traffic Congestion Analysis | Multi-modal regression for linear causal relationship description |
| [Multi-Temporal Relationship Inference in Urban Areas](https://doi.org/10.1145/3580305.3599440) | Shuangli Li, Jingbo Zhou, Ji Liu, Tong Xu, Enhong Chen, Hui Xiong | Finding multiple temporal relationships among locations can benefit a bunch of urban applications, such as dynamic offline advertising and smart public transport planning. While some efforts have been made on finding static relationships among locations, little attention is focused on studying time-aware location relationships. Indeed, abundant location-based human activities are time-varying and the availability of these data enables a new paradigm for understanding the dynamic relationships in a period among connective locations. To this end, we propose to study a new problem, namely multi-Temporal relationship inference among locations (Trial for short), where the major challenge is how to integrate dynamic and geographical influence under the relationship sparsity constraint. Specifically, we propose a solution to Trial with a graph learning scheme, which includes a spatially evolving graph neural network (SEENet) with two collaborative components: spatially evolving graph convolution module (SEConv) and spatially evolving self-supervised learning strategy (SE-SSL). SEConv performs the intra-time aggregation and inter-time propagation to capture the multifaceted spatially evolving contexts from the view of location message passing. In addition, SE-SSL designs time-aware self-supervised learning tasks in a global-local manner with additional evolving constraint to enhance the location representation learning and further handle the relationship sparsity. Finally, experiments on four real-world datasets demonstrate the superiority of our method over several state-of-the-art approaches. | Multi-Temporal relationship inference among locations (Trial) | Spatially Evolving Graph Neural Network (SEENet) |
| [Urban Region Representation Learning with OpenStreetMap Building Footprints](https://doi.org/10.1145/3580305.3599538) | Yi Li, Weiming Huang, Gao Cong, Hao Wang, Zheng Wang | The prosperity of crowdsourcing geospatial data provides increasing opportunities to understand our cities. In particular, OpenStreetMap (OSM) has become a prominent vault of geospatial data on the Web. In this context, learning urban region representations from OSM data, which is unexplored in previous work, could be profitable for various downstream tasks. In this work, we utilize OSM buildings (footprints) complemented with points of interest (POIs) to learn region representations, as buildings' shapes, spatial distributions, and properties have tight linkages to different urban functions. However, appealing as it seems, urban buildings often exhibit complex patterns to form dense or sparse areas, which brings significant challenges for unsupervised feature extraction. To address the challenges, we propose RegionDCL1, an unsupervised framework to deeply mine urban buildings. In a nutshell, we leverage random points generated by Poisson Disk Sampling to tackle data-sparse areas and utilize triplet loss with a novel adaptive margin to preserve inter-region correlations. Furthermore, we train our model with group-level and region-level contrastive learning, making it adaptive to varying region partitions. Extensive experiments in two global cities demonstrate that RegionDCL consistently outperforms the state-of-the-art counterparts across different region partitions, and outputs effective representations for inferring urban land use and population density. | Learning urban region representations from OpenStreetMap (OSM) data | RegionDCL1 (Region Deep Context Learning) |
| [Robust Spatiotemporal Traffic Forecasting with Reinforced Dynamic Adversarial Training](https://doi.org/10.1145/3580305.3599492) | Fan Liu, Weijia Zhang, Hao Liu | Machine learning-based forecasting models are commonly used in Intelligent Transportation Systems (ITS) to predict traffic patterns and provide city-wide services. However, most of the existing models are susceptible to adversarial attacks, which can lead to inaccurate predictions and negative consequences such as congestion and delays. Therefore, improving the adversarial robustness of these models is crucial for ITS. In this paper, we propose a novel framework for incorporating adversarial training into spatiotemporal traffic forecasting tasks. We demonstrate that traditional adversarial training methods designated for static domains cannot be directly applied to traffic forecasting tasks, as they fail to effectively defend against dynamic adversarial attacks. Then, we propose a reinforcement learning-based method to learn the optimal node selection strategy for adversarial examples, which simultaneously strengthens the dynamic attack defense capability and reduces the model overfitting. Additionally, we introduce a self-knowledge distillation regularization module to overcome the "forgetting issue" caused by continuously changing adversarial nodes during training. We evaluate our approach on two real-world traffic datasets and demonstrate its superiority over other baselines. Our method effectively enhances the adversarial robustness of spatiotemporal traffic forecasting models. The source code for our framework is available at https://github.com/usail-hkust/RDAT. | Spatiotemporal traffic forecasting | Reinforced Dynamic Adversarial Training |
| [Context-aware Event Forecasting via Graph Disentanglement](https://doi.org/10.1145/3580305.3599285) | Yunshan Ma, Chenchen Ye, Zijian Wu, Xiang Wang, Yixin Cao, Tat-Seng Chua | Event forecasting has been a demanding and challenging task throughout the entire human history. It plays a pivotal role in crisis alarming and disaster prevention in various aspects of the whole society. The task of event forecasting aims to model the relational and temporal patterns based on historical events and makes forecasting to what will happen in the future. Most existing studies on event forecasting formulate it as a problem of link prediction on temporal event graphs. However, such pure structured formulation suffers from two main limitations: 1) most events fall into general and high-level types in the event ontology, and therefore they tend to be coarse-grained and offers little utility which inevitably harms the forecasting accuracy; and 2) the events defined by a fixed ontology are unable to retain the out-of-ontology contextual information.To address these limitations, we propose a novel task of context-aware event forecasting which incorporates auxiliary contextual information. First, the categorical context provides supplementary fine-grained information to the coarse-grained events. Second and more importantly, the context provides additional information towards specific situation and condition, which is crucial or even determinant to what will happen next. However, it is challenging to properly integrate context into the event forecasting framework, considering the complex patterns in the multi-context scenario. Towards this end, we design a novel framework named Separation and Collaboration Graph Disentanglement (short as SeCoGD) for context-aware event forecasting. In the separation stage, we leverage the context as a prior guidance to disentangle the event graph into multiple sub-graphs, followed by a context-specific module to model the relational-temporal patterns within each context. In the collaboration stage, we design a cross-context module to retain the collaborative associations among multiple contexts. Since there is no available dataset for this novel task, we construct three large- scale datasets based on GDELT. Experimental results demonstrate hat our model outperforms a list of SOTA methods. The dataset and code are released via https://github.com/yecchen/SeCoGD. | Context-aware event forecasting | Separation and Collaboration Graph Disentanglement (SeCoGD) |
| [Causal Effect Estimation on Hierarchical Spatial Graph Data](https://doi.org/10.1145/3580305.3599269) | Koh Takeuchi, Ryo Nishida, Hisashi Kashima, Masaki Onishi | Estimating individual treatment effects from observational data is a fundamental problem in causal inference. To accurately estimate treatment effects in the spatial domain, we need to address certain aspects such as how to use the spatial coordinates of covariates and treatments and how the covariates and the treatments interact spatially. We introduce a new problem of predicting treatment effects on time series outcomes from spatial graph data with a hierarchical structure. To address this problem, we propose a spatial intervention neural network (SINet) that leverages the hierarchical structure of spatial graphs to learn a rich representation of the covariates and the treatments and exploits this representation to predict a time series of treatment outcome. Using a multi-agent simulator, we synthesized a crowd movement guidance dataset and conduct experiments to estimate the conditional average treatment effect, where we considered the initial locations of the crowds as covariates, route guidance as a treatment, and number of agents reaching a goal at each time stamp as the outcome. We employed state-of-the-art spatio-temporal graph neural networks and neural network-based causal inference methods as baselines, and show that our proposed method outperformed baselines both quantitatively and qualitatively. | Estimating individual treatment effects from observational data | Spatial Intervention Neural Network (SINet) |
| [Pattern Expansion and Consolidation on Evolving Graphs for Continual Traffic Prediction](https://doi.org/10.1145/3580305.3599463) | Binwu Wang, Yudong Zhang, Xu Wang, Pengkun Wang, Zhengyang Zhou, Lei Bai, Yang Wang | Recently, spatiotemporal graph convolutional networks are becoming popular in the field of traffic flow prediction and significantly improve prediction accuracy. However, the majority of existing traffic flow prediction models are tailored to static traffic networks and fail to model the continuous evolution and expansion of traffic networks. In this work, we move to investigate the challenge of traffic flow prediction on an expanding traffic network. And we propose an efficient and effective continual learning framework to achieve continuous traffic flow prediction without the access to historical graph data, namely Pattern Expansion and Consolidation based on Pattern Matching based (PECPM). Specifically, we first design a pattern bank based on pattern matching to store representative patterns of the road network. With the expansion of the road network, the model configured with such a bank module can achieve continuous traffic prediction by effectively managing patterns stored in the bank. The core idea is to continuously update new patterns while consolidating learned ones. Specifically, we design a pattern expansion mechanism that can detect evolved and new patterns from the updated network, then these unknown patterns are expanded into the pattern bank to adapt to the updated road network. Additionally, we propose a pattern consolidation mechanism that includes both a bank preservation mechanism and a pattern traceability mechanism. This can effectively consolidate the learned patterns in the bank without requiring access to detailed historical graph data. We construct experiments on real-world traffic datasets to demonstrate the competitive performance, superior efficiency, and strong generalization ability of PECPM. | Continual traffic flow prediction on an expanding traffic network | Pattern Expansion and Consolidation based on Pattern Matching (PECPM) |
| [Deep Bayesian Active Learning for Accelerating Stochastic Simulation](https://doi.org/10.1145/3580305.3599300) | Dongxia Wu, Ruijia Niu, Matteo Chinazzi, Alessandro Vespignani, Yi-An Ma, Rose Yu | Stochastic simulations such as large-scale, spatiotemporal, age-structured epidemic models are computationally expensive at fine-grained resolution. While deep surrogate models can speed up the simulations, doing so for stochastic simulations and with active learning approaches is an underexplored area. We propose Interactive Neural Process (INP), a deep Bayesian active learning framework for learning deep surrogate models to accelerate stochastic simulations. INP consists of two components, a spatiotemporal surrogate model built upon Neural Process (NP) family and an acquisition function for active learning. For surrogate modeling, we develop Spatiotemporal Neural Process (STNP) to mimic the simulator dynamics. For active learning, we propose a novel acquisition function, Latent Information Gain (LIG), calculated in the latent space of NP based models. We perform a theoretical analysis and demonstrate that LIG reduces sample complexity compared with random sampling in high dimensions. We also conduct empirical studies on three complex spatiotemporal simulators for reaction diffusion, heat flow, and infectious disease. The results demonstrate that STNP outperforms the baselines in the offline learning setting and LIG achieves the state-of-the-art for Bayesian active learning. |  | Interactive Neural Process (INP) |
| [Spatial Heterophily Aware Graph Neural Networks](https://doi.org/10.1145/3580305.3599510) | Congxi Xiao, Jingbo Zhou, Jizhou Huang, Tong Xu, Hui Xiong | Graph Neural Networks (GNNs) have been broadly applied in many urban applications upon formulating a city as an urban graph whose nodes are urban objects like regions or points of interest. Recently, a few enhanced GNN architectures have been developed to tackle heterophily graphs where connected nodes are dissimilar. However, urban graphs usually can be observed to possess a unique spatial heterophily property; that is, the dissimilarity of neighbors at different spatial distances can exhibit great diversity. This property has not been explored, while it often exists. To this end, in this paper, we propose a metric, named Spatial Diversity Score, to quantitatively measure the spatial heterophily and show how it can influence the performance of GNNs. Indeed, our experimental investigation clearly shows that existing heterophilic GNNs are still deficient in handling the urban graph with high spatial diversity score. This, in turn, may degrade their effectiveness in urban applications. Along this line, we propose a Spatial Heterophily Aware Graph Neural Network (SHGNN), to tackle the spatial diversity of heterophily of urban graphs. Based on the key observation that spatially close neighbors on the urban graph present a more similar mode of difference to the central node, we first design a rotation-scaling spatial aggregation module, whose core idea is to properly group the spatially close neighbors and separately process each group with less diversity inside. Then, a heterophily-sensitive spatial interaction module is designed to adaptively capture the commonality and diverse dissimilarity in different spatial groups. Extensive experiments on three real-world urban datasets demonstrate the superiority of our SHGNN over several its competitors. | Tackling the spatial diversity of heterophily in urban graphs | Spatial Heterophily Aware Graph Neural Network (SHGNN) |
| [Spatio-temporal Diffusion Point Processes](https://doi.org/10.1145/3580305.3599511) | Yuan Yuan, Jingtao Ding, Chenyang Shao, Depeng Jin, Yong Li | Spatio-temporal point process (STPP) is a stochastic collection of events accompanied with time and space. Due to computational complexities, existing solutions for STPPs compromise with conditional independence between time and space, which consider the temporal and spatial distributions separately. The failure to model the joint distribution leads to limited capacities in characterizing the spatio-temporal entangled interactions given past events. In this work, we propose a novel parameterization framework for STPPs, which leverages diffusion models to learn complex spatio-temporal joint distributions. We decompose the learning of the target joint distribution into multiple steps, where each step can be faithfully described by a Gaussian distribution. To enhance the learning of each step, an elaborated spatio-temporal co-attention module is proposed to capture the interdependence between the event time and space adaptively. For the first time, we break the restrictions on spatio-temporal dependencies in existing solutions, and enable a flexible and accurate modeling paradigm for STPPs. Extensive experiments from a wide range of fields, such as epidemiology, seismology, crime, and urban mobility, demonstrate that our framework outperforms the state-of-the-art baselines remarkably. Further in-depth analyses validate its ability to capture spatio-temporal interactions, which can learn adaptively for different scenarios. The datasets and source code are available online: https://github.com/tsinghua-fib-lab/Spatio-temporal-Diffusion-Point-Processes. | The task of this paper is to propose a novel parameterization framework for spatio-temporal point processes (STPP) that leverages diffusion models to learn complex spatio-temporal joint distributions. | The proposed framework decomposes the learning of the target joint distribution into multiple steps, where each step can be described by a Gaussian distribution. An elaborated spatio-temporal co-attention module is also introduced to capture the interdependence between event time and space. This framework enables flexible and accurate modeling for STPPs and breaks the restrictions on spatio-temporal dependencies in existing solutions. |
| [Spatial Clustering Regression of Count Value Data via Bayesian Mixture of Finite Mixtures](https://doi.org/10.1145/3580305.3599509) | Peng Zhao, Hou-Cheng Yang, Dipak K. Dey, Guanyu Hu | Investigating relationships between response variables and covariates in areas such as environmental science, geoscience, and public health is an important endeavor. Based on a Bayesian mixture of finite mixtures model, we present a novel spatially clustered coefficients regression model for count value data. The proposed method detects the spatial homogeneity of the Poisson regression coefficients. A Markov random field constrained mixture of finite mixtures prior provides a regularized estimator of the number of clusters of regression coefficients with geographical neighborhood information. As a by-product, we also provide the theoretical properties of our proposed method when the Markov random field is exchangeable. An efficient Markov chain Monte Carlo algorithm is developed by using the multivariate log gamma distribution as a base distribution. Simulation studies are carried out to examine the empirical performance of the proposed method. Additionally, we analyze Georgia's premature death data as an illustration of the effectiveness of our approach. The supplementary materials are provided on GitHub at https://github.com/pengzhaostat/MLG_MFM. | Investigating relationships between response variables and covariates in areas such as environmental science, geoscience, and public health | Spatially clustered coefficients regression model for count value data using a Bayesian mixture of finite mixtures model with a Markov random field constrained mixture of finite mixtures prior |
| [Generative Causal Interpretation Model for Spatio-Temporal Representation Learning](https://doi.org/10.1145/3580305.3599363) | Yu Zhao, Pan Deng, Junting Liu, Xiaofeng Jia, Jianwei Zhang | Learning, interpreting, and predicting from complex and high-dimensional spatio-temporal data is a natural ability of humans and other intelligent agents, and one of the most important and difficult challenges of AI. Although objects may present different observed phenomena under different situations, their causal mechanism and generation rules are stable and invariant. Different from most existing studies that focus on dynamic correlation, we explore the latent causal structure and mechanism of causal descriptors in the spatio-temporal dimension at the microscopic level, thus revealing the generation principle of observation. In this paper, we regard the causal mechanism as a spatio-temporal causal process modulated by non-stationary exogenous variables. To this end, we propose a theoretically-grounded Generative Causal Interpretation Model (GCIM), which infers explanatory-capable microscopic causal descriptors from observational data via spatio-temporal causal representations. The core of GCIM is to estimate the prior distribution of causal descriptors by using the spatio-temporal causal structure and transition process under the constraints of identifiable conditions, thus extending the Variational Auto Encoder (VAE). Furthermore, our method is able to automatically capture domain information from observations to model non-stationarity. We further analyze the model identifiability, showing that the proposed model learned from observations recovers the true one up to a certain degree. Experiments on synthetic and real-world datasets show that GCIM can successfully identify latent causal descriptors and structures, and accurately predict future data. | Learning, interpreting, and predicting from complex and high-dimensional spatio-temporal data | Generative Causal Interpretation Model (GCIM) |
| [Automatic Temporal Relation in Multi-Task Learning](https://doi.org/10.1145/3580305.3599261) | Menghui Zhou, Po Yang | Multi-task learning with temporal relation is a common prediction method for modelling the evolution of a wide range of systems. Considering the inherent relations between multiple time points, many works apply multi-task learning to jointly analyse all time points, with each time point corresponding to a prediction task. The most difficult challenge is determining how to fully explore and thus exploit the shared valuable temporal information between tasks to improve the generalization performance and robustness of the model. Existing works are classified as temporal smoothness and mean temporal relations. Both approaches, however, utilize a predefined and symmetric task relation structure that is too rigid and insufficient to adequately capture the intricate temporal relations between tasks. Instead, we propose a novel mechanism named Automatic Temporal Relation (AutoTR) for directly and automatically learning the temporal relation from any given dataset. To solve the biconvex objective function, we adopt the alternating optimization and show that the two related sub-optimization problems are amenable to closed-form computation of the proximal operator. To solve the two problems efficiently, the accelerated proximal gradient method is used, which has the fastest convergence rate of any first-order method. We have preprocessed six public real-life datasets and conducted extensive experiments to fully demonstrate the superiority of AutoTR. The results show that AutoTR outperforms several baseline methods on almost all datasets with different training ratios, in terms of overall model performance and every individual task performance. Furthermore, our findings verify that the temporal relation between tasks is asymmetrical, which has not been considered in previous works. The implementation source can be found at https://github.com/menghui-zhou/AutoTR. | Multi-Task Learning with Temporal Relation | Automatic Temporal Relation (AutoTR) |
| [Maintaining the Status Quo: Capturing Invariant Relations for OOD Spatiotemporal Learning](https://doi.org/10.1145/3580305.3599421) | Zhengyang Zhou, Qihe Huang, Kuo Yang, Kun Wang, Xu Wang, Yudong Zhang, Yuxuan Liang, Yang Wang | Spatiotemporal (ST) learning has become a crucial technique for urban digitalization. Due to expansions and dynamics of cities, current spatiotemporal models are inclined to suffer distribution shifts between training and testing sets, leading to the OOD delimma. However, few studies focus on such OOD problem in temporal regressions, let alone spatiotemporal learning. Spatiotemporal data usually reveals segment-level heterogeneity within periodicity and complex spatial dependencies, posing challenges to invariance extraction. In this paper, we find that ST relations make sense for generalization and devise a Causal ST learning framework, CauSTG, which enables invariant relation transferred to OOD scenarios. Specifically, we take temporal steps as environments, and transform spatial-temporal relations into learnable parameters. To tackle heterogeneity in periodicity, we partition temporal steps into sub-environments by identifying distinctive trend patterns, enabling re-organized samples trained separately. To extract invariance within ST observations, we propose a spatiotemporal consistency learner and a hierarchical invariance explorer to jointly filter out stable relations. Our spatiotemporal learner quantifies bi-directional spatial consistency and extracts disentangled seasonal-trend patterns via trainable parameters. Further, the hierarchical invariance explorer constructs variation-based filter to achieve both local and global invariances. Experiments reveal that CauSTG can increase at most 10.26% performance against best baselines, and visualized invariant relations can well interpret the physical rationales. The appendix and codes can be available in our Github repository. | Temporal regressions, spatiotemporal learning | Causal ST learning framework (CauSTG) |
| [ILRoute: A Graph-based Imitation Learning Method to Unveil Riders' Routing Strategies in Food Delivery Service](https://doi.org/10.1145/3580305.3599844) | Tao Feng, Huan Yan, Huandong Wang, Wenzhen Huang, Yuyang Han, Hongsen Liao, Jinghua Hao, Yong Li | Pick-up and delivery (PD) services such as online food ordering are playing an increasingly important role in serving people's daily demands. Accurate PD route prediction (PDRP) is important for service providers to efficiently schedule riders to improve service quality. It is crucial to model the decision-making process behind the route choice of riders for PDRP. Recent years have witnessed the success of utilizing imitation learning (IL) to model user decision-making process. Therefore, we propose to deploy an IL framework to solve the PDRP problem. However, there still exist three main challenges: (1) the rider's route decision is affected by multi-source and heterogeneous features and the complex relationships among these features make it hard to explore how they influence the rider's route decision-making; (2) the large route decision-making space make it easy to explore and predict unreasonable routes; (3) the rider's personalized preference is important in modeling the route decision-making process but cannot be fully explored. To tackle the above challenges, we propose ILRoute, a Graph-based imitation learning method for PDRP. ILRoute utilizes a multi-graph neural network (multi-GNN) to extract the multi-source and heterogeneous features and model their complex relationships. To address the large route decision-making space, ILRoute introduces a mobility regularity-aware constraint as prior route choice knowledge to reduce the exploration route decision-making space. To model the personalized preferences of the rider, ILRoute utilizes a personalized constraint mechanism to enhance the personalization of the rider's route decision-making process. Offline experiments conducted on three real-world datasets and online comparisons demonstrate the superiority of our proposed model. | Pick-up and delivery route prediction (PDRP) | Imitation learning (IL) using a multi-graph neural network (multi-GNN) |
| [iETA: A Robust and Scalable Incremental Learning Framework for Time-of-Arrival Estimation](https://doi.org/10.1145/3580305.3599842) | Jindong Han, Hao Liu, Shui Liu, Xi Chen, Naiqiang Tan, Hua Chai, Hui Xiong | Time-of-arrival estimation or Estimated Time of Arrival (ETA) has become an indispensable building block of modern intelligent transportation systems. While many efforts have been made for time-of-arrival estimation, most of them have scalability and robustness issues when dealing with real-world large-scale ETA scenarios, where billions of vehicle trajectories and ETA requests have been continuously generating every day. To this end, in this paper, we propose a robust and scalable incremental ETA learning framework, iETA, to continuously exploit spatio-temporal traffic patterns from massive floating-car data and thus achieve better estimation performances. Specifically, we first build an incremental travel time predictor that can be incrementally updated based on newly generated traffic data. The incremental travel time predictor not only reduces the overall learning overhead but also improves the model's robustness toward urban traffic distribution shifts. Then, we propose a historical traffic knowledge consolidation module to preserve critical spatio-temporal knowledge from previous ETA predictors under the incremental learning setting. Moreover, to reduce interference induced by low-quality traffic data, we propose an adversarial training module to improve the learning robustness by proactively mitigating and resisting traffic noise perturbations. Finally, extensive experiments demonstrate the effectiveness and efficiency of the proposed system against state-of-the-art baselines in large-scale ETA scenarios. Most importantly, iETA has been deployed on the Didi Chuxing platform, handling real-time billions of ETA queries every day, and substantially improves the prediction accuracy. | Time-of-arrival estimation | Incremental learning |
| [Large-scale Urban Cellular Traffic Generation via Knowledge-Enhanced GANs with Multi-Periodic Patterns](https://doi.org/10.1145/3580305.3599853) | Shuodi Hui, Huandong Wang, Tong Li, Xinghao Yang, Xing Wang, Junlan Feng, Lin Zhu, Chao Deng, Pan Hui, Depeng Jin, Yong Li | With the rapid development of the cellular network, network planning is increasingly important. Generating large-scale urban cellular traffic contributes to network planning via simulating the behaviors of the planned network. Existing methods fail in simulating the long-term temporal behaviors of cellular traffic while cannot model the influences of the urban environment on the cellular networks. We propose a knowledge-enhanced GAN with multi-periodic patterns to generate large-scale cellular traffic based on the urban environment. First, we design a GAN model to simulate the multi-periodic patterns and long-term aperiodic temporal dynamics of cellular traffic via learning the daily patterns, weekly patterns, and residual traffic between long-term traffic and periodic patterns step by step. Then, we leverage urban knowledge to enhance traffic generation via constructing a knowledge graph containing multiple factors affecting cellular traffic in the surrounding urban environment. Finally, we evaluate our model on a real cellular traffic dataset. Our proposed model outperforms three state-of-art generation models by over 32.77%, and the urban knowledge enhancement improves the performance of our model by 4.71%. Moreover, our model achieves good generalization and robustness in generating traffic for urban cellular networks without training data in the surrounding areas. | Large-scale urban cellular traffic generation | Knowledge-enhanced GAN with multi-periodic patterns |
| [Ball Trajectory Inference from Multi-Agent Sports Contexts Using Set Transformer and Hierarchical Bi-LSTM](https://doi.org/10.1145/3580305.3599779) | Hyunsung Kim, Han-Jun Choi, Chang Jo Kim, Jinsung Yoon, Sang-Ki Ko | As artificial intelligence spreads out to numerous fields, the application of AI to sports analytics is also in the spotlight. However, one of the major challenges is the difficulty of automated acquisition of continuous movement data during sports matches. In particular, it is a conundrum to reliably track a tiny ball on a wide soccer pitch with obstacles such as occlusion and imitations. Tackling the problem, this paper proposes an inference framework of ball trajectory from player trajectories as a cost-efficient alternative to ball tracking. We combine Set Transformers to get permutation-invariant and equivariant representations of the multi-agent contexts with a hierarchical architecture that intermediately predicts the player ball possession to support the final trajectory inference. Also, we introduce the reality loss term and postprocessing to secure the estimated trajectories to be physically realistic. The experimental results show that our model provides natural and accurate trajectories as well as admissible player ball possession at the same time. Lastly, we suggest several practical applications of our framework including missing trajectory imputation, semi-automated pass annotation, automated zoom-in for match broadcasting, and calculating possession-wise running performance metrics. | Ball trajectory inference from player trajectories | Set Transformer and Hierarchical Bi-LSTM |
| [Real Time Index and Search Across Large Quantities of GNN Experts for Low Latency Online Learning](https://doi.org/10.1145/3580305.3599893) | Johan Kok Zhi Kang, Sien Yi Tan, Bingsheng He, Zhen Zhang | Online learning is a powerful technique that allows models to adjust to concept drift in dynamically changing graphs. This approach is crucial for large mobility-based companies like Grab, where batch-learning methods fail to keep up with the large amount of training data. Our work focuses on scaling graph neural network mixture of expert (MoE) models for real-time traffic speed prediction on road networks, while meeting high accuracy and low latency requirements. Conventional spatio-temporal and incremental MoE frameworks struggle with poor inference accuracy and linear time complexity when scaling experts, for the latter, leading to prohibitively high latency in model updates. To address this issue, we introduce the Indexed Router, a novel method that categorizes experts into a structured hierarchy called the indexed tree. This approach reduces the time to scale and search N number of experts from O(N) to O(log N), making it ideal for online learning under tight service level agreements. Our experiments show that these time savings do not compromise inference accuracy, and our Indexed Router outperforms state-of-the-art spatio-temporal and incremental MoE models in terms of traffic speed prediction accuracy on real-life GPS traces from Grab's database and publicly available records. In summary, the Indexed Router enables MoE models to scale across large numbers of experts with low latency, while accurately identifying the relevant experts for inference. | Real-time traffic speed prediction on road networks | Indexed Router |
| [A Preference-aware Meta-optimization Framework for Personalized Vehicle Energy Consumption Estimation](https://doi.org/10.1145/3580305.3599767) | Siqi Lai, Weijia Zhang, Hao Liu | Vehicle Energy Consumption (VEC) estimation aims to predict the total energy required for a given trip before it starts, which is of great importance to trip planning and transportation sustainability. Existing approaches mainly focus on extracting statistically significant factors from typical trips to improve the VEC estimation. However, the energy consumption of each vehicle may diverge widely due to the personalized driving behavior under varying travel contexts. To this end, this paper proposes a preference-aware meta-optimization framework Meta-Pec for personalized vehicle energy consumption estimation. Specifically, we first propose a spatiotemporal behavior learning module to capture the latent driver preference hidden in historical trips. Moreover, based on the memorization of driver preference, we devise a selection-based driving behavior prediction module to infer driver-specific driving patterns on a given route, which provides additional basis and supervision signals for VEC estimation. Besides, a driver-specific meta-optimization scheme is proposed to enable fast model adaption by learning and sharing transferable knowledge globally. Extensive experiments on two real-world datasets show the superiority of our proposed framework against ten numerical and data-driven machine learning baselines. The source code is available at https://github.com/usail-hkust/Meta-Pec. | Vehicle Energy Consumption (VEC) estimation | Meta-Pec framework |
| [DisasterNet: Causal Bayesian Networks with Normalizing Flows for Cascading Hazards Estimation from Satellite Imagery](https://doi.org/10.1145/3580305.3599807) | Xuechun Li, Paula M. Bürgi, Wei Ma, Hae Young Noh, David Jay Wald, Susu Xu | Sudden-onset hazards like earthquakes often induce cascading secondary hazards (e.g., landslides, liquefaction, debris flows, etc.) and subsequent impacts (e.g., building and infrastructure damage) that cause catastrophic human and economic losses. Rapid and accurate estimates of these hazards and impacts are critical for timely and effective post-disaster responses. Emerging remote sensing techniques provide pre- and post-event satellite images for rapid hazard estimation. However, hazards and damage often co-occur or colocate with underlying complex cascading geophysical processes, making it challenging to directly differentiate multiple hazards and impacts from satellite imagery using existing single-hazard models. We introduce DisasterNet, a novel family of causal Bayesian networks to model processes that a major hazard triggers cascading hazards and impacts and further jointly induces signal changes in remotely sensed observations. We integrate normalizing flows to effectively model the highly complex causal dependencies in this cascading process. A triplet loss is further designed to leverage prior geophysical knowledge to enhance the identifiability of our highly expressive Bayesian networks. Moreover, a novel stochastic variational inference with normalizing flows is derived to jointly approximate posteriors of multiple unobserved hazards and impacts from noisy remote sensing observations. Integrating with the USGS Prompt Assessment of Global Earthquakes for Response (PAGER) system, our framework is evaluated in recent global earthquake events. Evaluation results show that DisasterNet significantly improves multiple hazard and impact estimation compared to existing USGS products. | Cascading hazards estimation from satellite imagery | DisasterNet, a family of causal Bayesian networks with normalizing flows |
| [Learning Joint Relational Co-evolution in Spatial-Temporal Knowledge Graph for SMEs Supply Chain Prediction](https://doi.org/10.1145/3580305.3599855) | Youru Li, Zhenfeng Zhu, Xiaobo Guo, Linxun Chen, Zhouyin Wang, Yinmeng Wang, Bing Han, Yao Zhao | To effectively explore the supply chain relationships among Small and Medium-sized Enterprises (SMEs), some remarkable progress in such a relation modeling problem, especially knowledge graph-based methods have been witnessed during these years. As a typical link prediction task, supply chain prediction can usually predict the unknown future relationship facts between SMEs by utilizing the historical semantic connections between entities in knowledge graphs (KGs). However, it is still a great challenge for existing models as seldom of them can consider both temporal dependency and cooperative correlation of the connectivity pattern along the timeline synergistically. Accordingly, we propose a novel framework to learn joint relational co-evolution in Spatial-Temporal Knowledge Graphs (STKG). Specifically, on the base of the constructed large-scale financial STKG, a multi-view relational sequences mining method is proposed to reveal the semantic information from ontological concepts. Furthermore, a relational co-evolution learning module is also developed to capture the regularity of evolving connectivity patterns from the spatial-temporal view. Meanwhile, a multiple random subspace representation learning layer is also designed to improve both compatibility and complementarity during knowledge aggregation. Experimental results on large-scale SMEs supply chain prediction tasks from four real-world industries in China have illustrated the effectiveness of the proposed model. | Supply chain prediction | Spatial-Temporal Knowledge Graph (STKG), multi-view relational sequences mining, relational co-evolution learning, multiple random subspace representation learning |
| [CBLab: Supporting the Training of Large-scale Traffic Control Policies with Scalable Traffic Simulation](https://doi.org/10.1145/3580305.3599789) | Chumeng Liang, Zherui Huang, Yicheng Liu, Zhanyu Liu, Guanjie Zheng, Hanyuan Shi, Kan Wu, Yuhao Du, Fuliang Li, Zhenhui Jessie Li | Traffic simulation provides interactive data for the optimization of traffic control policies. However, existing traffic simulators are limited by their lack of scalability and shortage in input data, which prevents them from generating interactive data from traffic simulation in the scenarios of real large-scale city road networks.In this paper, we present City Brain Lab, a toolkit for scalable traffic simulation. CBLab consists of three components: CBEngine, CBData, and CBScenario. CBEngine is a highly efficient simulator supporting large-scale traffic simulation. CBData includes a traffic dataset with road network data of 100 cities all around the world. We also develop a pipeline to conduct a one-click transformation from raw road networks to input data of our traffic simulation. Combining CBEngine and CBData allows researchers to run scalable traffic simulations in the road network of real large-scale cities. Based on that, CBScenario implements an interactive environment and a benchmark for two scenarios of traffic control policies respectively, with which traffic control policies adaptable for large-scale urban traffic can be trained and tuned. To the best of our knowledge, CBLab is the first infrastructure supporting traffic control policy optimization in large-scale urban scenarios. CBLab has supported the City Brain Challenge @ KDD CUP 2021. The project is available on GitHub:~https://github.com/CityBrainLab/CityBrainLab.git. | Supporting the training of large-scale traffic control policies with scalable traffic simulation | City Brain Lab (CBLab) - toolkit for scalable traffic simulation that includes CBEngine, CBData, and CBScenario |
| [Uncertainty-Aware Probabilistic Travel Time Prediction for On-Demand Ride-Hailing at DiDi](https://doi.org/10.1145/3580305.3599925) | Hao Liu, Wenzhao Jiang, Shui Liu, Xi Chen | Travel Time Estimation (TTE) aims to accurately forecast the expected trip duration from an origin to a destination. As one of the world's largest ride-hailing platforms, DiDi answers billions of TTE queries per day. The quality of TTE directly decides the customer's experience and the effectiveness of passenger-to-driver matching. However, existing studies mainly regard TTE as a deterministic regression problem and focus on improving the prediction accuracy of a single label, which overlooks the travel time uncertainty induced by various dynamic contextual factors. To this end, in this paper, we propose a probabilistic framework, ProbTTE, for uncertainty-aware travel time prediction. Specifically, the framework first transforms the single-label regression task to a multi-class classification problem to estimate the implicit travel time distribution. Moreover, we propose an adaptive local label-smoothing scheme to capture the ordinal inter-class relationship among soft travel time labels. Furthermore, we construct a route-wise log-normal distribution regularizer to absorb prior knowledge from large-scale historical trip data. By explicitly considering the travel uncertainty, the proposed approach not only improves the TTE accuracy but also provides additional travel time information to benefit downstream tasks in ride-hailing. Extensive experiments on real-world datasets demonstrate the superiority of the proposed framework compared with state-of-the-art travel time prediction algorithms. In addition, ProbTTE has been deployed in production at DiDi in late 2022 to empower various order dispatching services, and improves passenger and driver experiences significantly. | Travel Time Estimation (TTE) | Probabilistic framework called ProbTTE, multi-class classification, adaptive local label-smoothing scheme, route-wise log-normal distribution regularizer |
| [Practical Synthetic Human Trajectories Generation Based on Variational Point Processes](https://doi.org/10.1145/3580305.3599888) | Qingyue Long, Huandong Wang, Tong Li, Lisi Huang, Kun Wang, Qiong Wu, Guangyu Li, Yanping Liang, Li Yu, Yong Li | Human trajectories, reflecting people's travel patterns and the range of activities, are crucial for the applications like urban planning and epidemic control. However, the real-world human trajectory data tends to be limited by user privacy or device acquisition issues, leading to its insufficient quality to support the above applications. Hence, generating human trajectory data is a crucial but challenging task, which suffers from the following two critical challenges: 1) how to capture the user distribution in human trajectories (group view), and 2) how to model the complex mobility patterns of each user trajectory (individual view). In this paper, we propose a novel human trajectories generator (named VOLUNTEER), consisting of a user VAE and a trajectory VAE, to address the above challenges. Specifically, in the user VAE, we propose to learn the user distribution with all human trajectories from a group view. In the trajectory VAE, from the individual view, we model the complex mobility patterns by decoupling travel time and dwell time to accurately simulate individual trajectories. Extensive experiments on two real-world datasets show the superiority of our model over the state-of-the-art baselines. Further application analysis in the industrial system also demonstrates the effectiveness of our model. | Generating human trajectory data | Proposed method named VOLUNTEER, consisting of a user VAE (Variational Autoencoder) and a trajectory VAE |
| [SAInf: Stay Area Inference of Vehicles using Surveillance Camera Records](https://doi.org/10.1145/3580305.3599952) | Zhipeng Ma, Chuishi Meng, Huimin Ren, Sijie Ruan, Jie Bao, Xiaoting Wang, Tianrui Li, Yu Zheng | Stay area detection is one of the most important applications in trajectory data mining, which is helpful to understand human's behavior intentions. Traditional stay area detection methods are based on GPS data with relatively high sampling rate. However, because of privacy issues, accessing GPS data can be difficult in most real-world applications. Fortunately, traffic surveillance cameras have been widely deployed in urban area, and it provides us a novel way of acquiring vehicles' trajectories. All the vehicles that traverse by can be recognized and recorded in a passive way. However, the trajectory data collected in this way is extremely coarse, because the surveillance cameras are only deployed in important locations, such as crossroads. This coarse trajectory introduces two challenges for the stay area detection problem, i.e., whether and where the stay event occurs. In this paper, we design a two-stage method to solve the stay area detection problem with coarse trajectories. It first detects the stay event between a surveillance camera record pair, then uses a layer-by-layer stay area identification algorithm to infer the exact stay area. Extensive experiments based on real-world data were used to evaluate the performance of the proposed framework. Results demonstrate the proposed framework SAInf achieved a 58% performance improvement compared with SOTA methods. | Stay area detection | Two-stage method: stay event detection and stay area identification algorithm |
| [Detecting Vulnerable Nodes in Urban Infrastructure Interdependent Network](https://doi.org/10.1145/3580305.3599804) | Jinzhu Mao, Liu Cao, Chen Gao, Huandong Wang, Hangyu Fan, Depeng Jin, Yong Li | Understanding and characterizing the vulnerability of urban infrastructures, which refers to the engineering facilities essential for the regular running of cities and that exist naturally in the form of networks, is of great value to us. Potential applications include protecting fragile facilities and designing robust topologies, etc. Due to the strong correlation between different topological characteristics and infrastructure vulnerability and their complicated evolution mechanisms, some heuristic and machine assisted analysis fall short in addressing such a scenario. In this paper, we model the interdependent network as a heterogeneous graph and propose a system based on graph neural network with reinforcement learning, which can be trained on real-world data, to characterize the vulnerability of the city system accurately. The presented system leverages deep learning techniques to understand and analyze the heterogeneous graph, which enables us to capture the risk of cascade failure and discover vulnerable infrastructures of cities. Extensive experiments with various requests demonstrate not only the expressive power of our system but also transferring ability and necessity of the specific components. All source codes and models including those that can reproduce all figures analyzed in this work are publicly available at this link: https://github.com/tsinghua-fib-lab/KDD2023-ID546-UrbanInfra. |  | Graph neural network with reinforcement learning |
| [DRL4Route: A Deep Reinforcement Learning Framework for Pick-up and Delivery Route Prediction](https://doi.org/10.1145/3580305.3599811) | Xiaowei Mao, Haomin Wen, Hengrui Zhang, Huaiyu Wan, Lixia Wu, Jianbin Zheng, Haoyuan Hu, Youfang Lin | Pick-up and Delivery Route Prediction (PDRP), which aims to estimate the future service route of a worker given his current task pool, has received rising attention in recent years. Deep neural networks based on supervised learning have emerged as the dominant model for the task because of their powerful ability to capture workers' behavior patterns from massive historical data. Though promising, they fail to introduce the non-differentiable test criteria into the training process, leading to a mismatch in training and test criteria. Which considerably trims down their performance when applied in practical systems. To tackle the above issue, we present the first attempt to generalize Reinforcement Learning (RL) to the route prediction task, leading to a novel RL-based framework called DRL4Route. It combines the behavior-learning abilities of previous deep learning models with the non-differentiable objective optimization ability of reinforcement learning. DRL4Route can serve as a plug-and-play component to boost the existing deep learning models. Based on the framework, we further implement a model named DRL4Route-GAE for PDRP in logistic service. It follows the actor-critic architecture which is equipped with a Generalized Advantage Estimator that can balance the bias and variance of the policy gradient estimates, thus achieving a more optimal policy. Extensive offline experiments and the online deployment show that DRL4Route-GAE improves Location Square Deviation (LSD) by 0.9%-2.7%, and Accuracy@3 (ACC@3) by 2.4%-3.2% over existing methods on the real-world dataset. | Pick-up and Delivery Route Prediction (PDRP) | DRL4Route: Deep Reinforcement Learning (RL)-based framework |
| [QTNet: Theory-based Queue Length Prediction for Urban Traffic](https://doi.org/10.1145/3580305.3599890) | Ryu Shirakami, Toshiya Kitahara, Koh Takeuchi, Hisashi Kashima | Smart traffic management is the cornerstone of Intelligent Transport Systems (ITS). To achieve smooth travel in urban road networks, ITS provide software-based traffic management based on traffic forecasts. Recently, spatial-temporal graph neural networks (STGNNs) have achieved significant improvements in traffic forecasting by taking into account spatial and temporal dependencies in traffic data. However, in spite of being an indispensable statistic in traffic management in urban areas, the length of congestion queues has not been a prediction target. In addition, existing methods have not considered the use of multimodal traffic data for forecasting. Moreover, given the significant impact of ITS on the real world, black-box predictions with less explainability are unreliable. In this paper, we propose aQueueing-theory-based Neural Network (QTNet), which combines data-driven STGNN methods with queueing-theory-based domain knowledge of traffic engineering in order to achieve accurate and explainable predictions. In our queue length prediction experiments using a real-world dataset collected in urban areas of Tokyo, QTNet outperformed the baseline methods including the state-of-the-art STGNNs by 12.6% in RMSE and 9.9% MAE, and particularly for severe congestion, by 8.1% and 8.4%. | Queue length prediction | Queueing-theory-based Neural Network (QTNet) |
| [Deep Transfer Learning for City-scale Cellular Traffic Generation through Urban Knowledge Graph](https://doi.org/10.1145/3580305.3599801) | Shiyuan Zhang, Tong Li, Shuodi Hui, Guangyu Li, Yanping Liang, Li Yu, Depeng Jin, Yong Li | The problem of cellular traffic generation in cities without historical traffic data is critical and urgently needs to be solved to assist 5G base station deployments in mobile networks. In this paper, we propose ADAPTIVE, a deep transfer learning framework for city-scale cellular traffic generation through the urban knowledge graph. ADAPTIVE leverages historical data from other cities that have deployed 5G networks to assist cities that are newly deploying 5G networks through deep transfer learning. Specifically, ADAPTIVE can align the representations of base stations in the target city and source city while considering the environmental factors of cities, spatial and environmental contextual relations between base stations, and traffic temporal patterns at base stations. We next design a feature-enhanced generative adversarial network, which is trained based on the historical traffic data and representations of base stations in the source city. By feeding the aligned target city's base station representations into the trained model, we can then obtain the generated traffic data for the target city. Extensive experiments on real-world cellular traffic datasets show that ADAPTIVE generally outperforms state-of-the-art baselines by more than 40% in terms of Jensen-Shannon divergence and root-mean-square error. Also, ADAPTIVE has strong robustness based on the results of various cross-city experiments. ADAPTIVE has been successfully deployed on the 'Jiutian' Artificial Intelligence Platform of China Mobile to support cellular traffic generation and assist in the construction and operation of mobile networks. | City-scale cellular traffic generation | ADAPTIVE (deep transfer learning framework) with feature-enhanced generative adversarial network |
| [Hierarchical Reinforcement Learning for Dynamic Autonomous Vehicle Navigation at Intelligent Intersections](https://doi.org/10.1145/3580305.3599839) | Qian Sun, Le Zhang, Huan Yu, Weijia Zhang, Yu Mei, Hui Xiong | Recent years have witnessed the rapid development of the Cooperative Vehicle Infrastructure System (CVIS), where road infrastructures such as traffic lights (TL) and autonomous vehicles (AVs) can share information among each other and work collaboratively to provide safer and more comfortable transportation experience to human beings. While many efforts have been made to develop efficient and sustainable CVIS solutions, existing approaches on urban intersections heavily rely on domain knowledge and physical assumptions, preventing them from being practically applied. To this end, this paper proposes NavTL, a learning-based framework to jointly control traffic signal plans and autonomous vehicle rerouting in mixed traffic scenarios where human-driven vehicles and AVs co-exist. The objective is to improve travel efficiency and reduce total travel time by minimizing congestion at the intersections while guiding AVs to avoid the temporally congested roads. Specifically, we design a graph-enhanced multi-agent decentralized bi-directional hierarchical reinforcement learning framework by regarding TLs as manager agents and AVs as worker agents. At lower temporal resolution timesteps, each manager sets a goal for the workers within its controlled region. Simultaneously, managers learn to take the signal actions based on the observation from the environment as well as an intention information extracted from its workers. At higher temporal resolution timesteps, each worker makes rerouting decisions along its way to the destination based on its observation from the environment, an intention-enhanced manager state representation, and a goal from its present manager. Finally, extensive experiments on one synthetic and two real-world network-level datasets demonstrate the effectiveness of our proposed framework in terms of improving travel efficiency. | Joint control of traffic signal plans and autonomous vehicle rerouting in mixed traffic scenarios | Graph-enhanced multi-agent decentralized bi-directional hierarchical reinforcement learning |
| [Removing Camouflage and Revealing Collusion: Leveraging Gang-crime Pattern in Fraudster Detection](https://doi.org/10.1145/3580305.3599895) | Lewen Wang, Haozhe Zhao, Cunguang Feng, Weiqing Liu, Congrui Huang, Marco Santoni, Manuel Cristofaro, Paola Jafrancesco, Jiang Bian | As one of the major threats to the healthy development of various online platforms, fraud has become increasingly committed in the form of gangs since collusive fraudulent activities are much easier to obtain illicit benefits with lower exposure risk. To detect fraudsters in a gang, spatio-temporal graph neural network models have been widely applied to detect both temporal and spatial collusive patterns. However, a closer peek into real-world records of fraudsters can reveal that fraud gangs usually conduct community-level camouflage, specified by two types, i.e., temporal and spatial camouflage. Such camouflage can disguise gangs as benign communities by concealing collusive patterns and thus deceiving many existing graph neural network models. In the meantime, many existing graph neural network models suffer from the challenge of extreme sample imbalance caused by rare fraudsters hidden among massive users. To handle all these challenges, in this paper, we propose a generative adversarial network framework, named Adversarial Camouflage Detector, to detect fraudsters. Concretely, this ACD framework consists of four modules, in charge of community division, camouflage identification, fraudster detection, and camouflage generation, respectively. The first three modules form up a discriminator that uses spatio-temporal graph neural networks as the foundation model and enhance fraudster detection by amplifying the gangs' collusive patterns through automatically identifying and removing camouflage. Meanwhile, the camouflage generation module plays as the generator role that generates fraudsters samples by competing against the discriminator to alleviate the challenge of sample imbalance and increase the model robustness. The experimental result shows that our proposed method outperforms other methods on real-world datasets. | Fraudster detection | Generative adversarial network framework (Adversarial Camouflage Detector) |
| [A Predict-Then-Optimize Couriers Allocation Framework for Emergency Last-mile Logistics](https://doi.org/10.1145/3580305.3599766) | Kaiwen Xia, Li Lin, Shuai Wang, Haotian Wang, Desheng Zhang, Tian He | In recent years, emergency last-mile logistics (ELML) have played an essential role in urban emergencies. The efficient allocation of couriers in ELML is of practical significance to ensure the supply of essential materials, especially in public health emergencies (PHEs). However, couriers allocation becomes challenging due to the instability of demand, dynamic supply comprehension, and the evolutional delivery environment for ELML caused by PHEs. While existing work has delved into couriers allocation, the impact of PHEs on demand-supply-delivery has yet to be considered. In this work, we design PTOCA, a Predict-Then-Optimize Couriers Allocation framework. Specifically, in the prediction stage, we design a resource-aware prediction module that performs spatio-temporal modeling of unstable demand characteristics using a variational graph GRU encoder and builds a task-resource regressor to predict demand accurately. In the optimization stage, firstly, the priority ranking module solves the matching of delivery resources under demand-supply imbalance. Then the multi-factor task allocation module is used to model the dynamic evolutional environment and reasonably assign the delivery tasks of couriers. We evaluate PTOCA using real-world data covering 170 delivery zones, more than 10,000 couriers, and 100 million delivery tasks. The data is collected from JD Logistics, one of the largest logistics service companies. Extensive experimental results show that our method outperforms the baseline in task delivery rate and on-time delivery rate. | Efficient allocation of couriers in emergency last-mile logistics | PTOCA (Predict-Then-Optimize Couriers Allocation) framework |
| [NEON: Living Needs Prediction System in Meituan](https://doi.org/10.1145/3580305.3599874) | Xiaochong Lan, Chen Gao, Shiqi Wen, Xiuqi Chen, Yingge Che, Han Zhang, Huazhou Wei, Hengliang Luo, Yong Li | Living needs refer to the various needs in human's daily lives for survival and well-being, including food, housing, entertainment, etc. At life service platforms that connect users to service providers, such as Meituan, the problem of living needs prediction is fundamental as it helps understand users and boost various downstream applications such as personalized recommendation. However, the problem has not been well explored and is faced with two critical challenges. First, the needs are naturally connected to specific locations and times, suffering from complex impacts from the spatiotemporal context. Second, there is a significant gap between users' actual living needs and their historical records on the platform. To address these two challenges, we design a system of living NEeds predictiON named NEON, consisting of three phases: feature mining, feature fusion and multi-task prediction. In the feature mining phase, we carefully extract individual-level user features for spatiotemporal modeling, and aggregated-level behavioral features for enriching data, which serve as the basis for addressing two challenges, respectively. Further, in the feature fusion phase, we propose a neural network that effectively fuses two parts of features into the user representation. Moreover, we design a multitask prediction phase, where the auxiliary task of needs-meeting way prediction can enhance the modeling of spatiotemporal context. Extensive offline evaluations verify that our NEON system can effectively predict users' living needs. Furthermore, we deploy NEON into Meituan's algorithm engine and evaluate how it enhances the three downstream prediction applications, via large-scale online A/B testing. As a representative result, deploying our system leads to a 1.886% increase w.r.t. CTCVR in Meituan homepage recommendation. The results demonstrate NEON's effectiveness in predicting fine-grained user needs, needs-meeting way, and potential needs, highlighting the immense application value of NEON. | Living needs prediction | NEON system (consisting of three phases: feature mining, feature fusion, and multi-task prediction) |
| [Learning Multivariate Hawkes Process via Graph Recurrent Neural Network](https://doi.org/10.1145/3580305.3599857) | Kanghoon Yoon, Youngjun Im, Jingyu Choi, Taehwan Jeong, Jinkyoo Park | This paper presents a novel approach for modeling and predicting patterns of events in time-series learning, named graph recurrent temporal point process (GRTPP). Prior research has focused on using deep learning techniques, such as recurrent neural networks (RNNs) or attention-based sequential data embedding, on modeling the time-varying intensity of events. However, these models were typically limited to modeling a single intensity function capturing the event occurrence of all event types simultaneously. GRTPP addresses this issue by encoding multivariate event sequences into a sequence of graphs, where each node contains information about the event occurrence and time. The sequence of graphs is then embedded into node embeddings for each event type, taking into account the relationships between the event types. By integrating the estimated intensity functions, GRTPP predicts the event type and the timing of the next event. The proposed GRTPP model offers improved effectiveness and explainability compared to previous models, as demonstrated through empirical evaluations on five real-world datasets and the actual credit card transaction dataset. The code is available at https://github.com/im0j/GRTPP https://github.com/im0j/GRTPP. | Modeling and predicting patterns of events in time-series learning | Graph Recurrent Temporal Point Process (GRTPP) |
| [Commonsense Knowledge Graph towards Super APP and Its Applications in Alipay](https://doi.org/10.1145/3580305.3599791) | Xiaoling Zang, Binbin Hu, Jun Chu, Zhiqiang Zhang, Guannan Zhang, Jun Zhou, Wenliang Zhong | The recently explosive growth of Super Apps brings great convenience to people's daily life by providing a wide variety of services through mini-programs, including online shopping, travel, finance, and so on. Due to the considerable gap between various scenarios, the restriction of effective information transfer and sharing severely blocks the efficient delivery of online services, potentially affecting the user's app experience. To deeply understand users' needs, we propose SupKG, a commonsense knowledge graph towards Super APP to help comprehensively characterize user behaviors across different business scenarios. In particular, our SupKG is carefully established from multiplex and heterogeneous data source in Alipay (a well-known Super App in China), which also emphasize abundant spatiotemporal relations and intent-related entities to answer the fundamental question in life service ''which service do users need at what time and where''.On the hand, the successful application of SupKG hinges on the effective form of network representation ie Knowledge Graph Embedding (KGE). However, a series of unsatisfying issues still need to be carefully considered in the industrial environment: i) bridging language representations with knowledge structure in a unified manner, ii) alleviating the skewed data distribution in SupKG, and iii) effectively characterizing hierarchical structures in SupKG. With these motivations, we develop a novel knowledge graph representation learning framework for SupKG, enabling various downstream applications to benefit from learned representations of entities and relations. Extensive experiments on the standard knowledge graph completion task demonstrate the consistent and significant performance improvement of our representation learning framework, which also greatly benefits the supplementation of potential knowledge of SupKG. Towards real-world applications in Alipay, our SupKG and learned representations show the potential superiority of integrating global behaviors in cold-start scenarios and providing high-quality knowledge for warming up the graph-based ranking. | Characterizing user behaviors in different business scenarios and providing online services | Knowledge Graph Embedding (KGE) |
| [Road Planning for Slums via Deep Reinforcement Learning](https://doi.org/10.1145/3580305.3599901) | Yu Zheng, Hongyuan Su, Jingtao Ding, Depeng Jin, Yong Li | Millions of slum dwellers suffer from poor accessibility to urban services due to inadequate road infrastructure within slums, and road planning for slums is critical to the sustainable development of cities. Existing re-blocking or heuristic methods are either time-consuming which cannot generalize to different slums, or yield sub-optimal road plans in terms of accessibility and construction costs. In this paper, we present a deep reinforcement learning based approach to automatically layout roads for slums. We propose a generic graph model to capture the topological structure of a slum, and devise a novel graph neural network to select locations for the planned roads. Through masked policy optimization, our model can generate road plans that connect places in a slum at minimal construction costs. Extensive experiments on real-world slums in different countries verify the effectiveness of our model, which can significantly improve accessibility by 14.3% against existing baseline methods. Further investigations on transferring across different tasks demonstrate that our model can master road planning skills in simple scenarios and adapt them to much more complicated ones, indicating the potential of applying our model in real-world slum upgrading. The code and data are available at https://github.com/tsinghua-fib-lab/road-planning-for-slums. | Road planning for slums | Deep reinforcement learning based approach |
| [Online Few-Shot Time Series Classification for Aftershock Detection](https://doi.org/10.1145/3580305.3599879) | Sheng Zhong, Vinicius M.A. Souza, Glenn Eli Baker, Abdullah Mueen | Seismic monitoring systems sift through seismograms in real-time, searching for target events, such as underground explosions. In this monitoring system, a burst of aftershocks (minor earthquakes occur after a major earthquake over days or even years) can be a source of confounding signals. Such a burst of aftershock signals can overload the human analysts of the monitoring system. To alleviate this burden at the onset of a sequence of events (e.g., aftershocks), a human analyst can label the first few of these events and start an online classifier to filter out subsequent aftershock events. We propose an online few-shot classification model FewSig for time series data for the above use case. The framework of FewSig consists of a selective model to identify the high-confidence positive events which are used for updating the models and a general classifier to label the remaining events. Our specific technique uses a %two-level decision tree selective model based on sliding DTW distance and a general classifier model based on distance metric learning with Neighborhood Component Analysis (NCA). The algorithm demonstrates surprising robustness when tested on univariate datasets from the UEA/UCR archive. Furthermore, we show two real-world earthquake events where the FewSig reduces the human effort in monitoring applications by filtering out the aftershock events. | Aftershock detection in seismic monitoring systems | Online few-shot classification model FewSig |
| [The 12th International Workshop on Urban Computing](https://doi.org/10.1145/3580305.3599581) | Chuishi Meng, Yanhua Li, Yu Zheng, Jieping Ye, Qiang Yang, Philip S. Yu, Ouri Wolfson | Urbanization's rapid progress has led to many big cities, which have modernized many people's lives but also engendered big challenges, such as air pollution, increased energy consumption and traffic congestion. Tackling these challenges were nearly impossible years ago given the complex and dynamic settings of cities. Nowadays, sensing technologies and large-scale computing infrastructures have produced a variety of big data in urban spaces, e.g., human mobility, air quality, traffic patterns, and geographical data. Motivated by the opportunities of building more intelligent cities, we came up with a vision of urban computing, which aims to unlock the power of knowledge from big and heterogeneous data collected in urban spaces and apply this powerful information to solve major issues our cities face today. |  |  |
| [The 9th SIGKDD International Workshop on Mining and Learning from Time Series](https://doi.org/10.1145/3580305.3599214) | Sanjay Purushotham, Dongjin Song, Qingsong Wen, Jun Huan, Cong Shen, Yuriy Nevmyvaka | Time series data has become pervasive across domains such as finance, transportation, retail, entertainment, and healthcare. This shift towards continuous monitoring and recording, fueled by advancements in sensing technologies, necessitates the development of new tools and solutions. Despite extensive study, the importance of time series analysis continues to increase. However, modern time series data present challenges to existing techniques, including irregular sampling and spatiotemporal structures. Time series mining research is both challenging and rewarding as it connects diverse disciplines and requires interdisciplinary solutions. The goals of this workshop are to (1) highlight the significant challenges that underpin learning and mining from time series data (e.g., irregular sampling, spatiotemporal structure, uncertainty quantification), (2) discuss recent algorithmic, theoretical, statistical, or systems-based developments for tackling these problems, and (3) to synergize the research activities and discuss both new and open problems in time series analysis and mining. In summary, our workshop will focus on both the theoretical and practical aspects of time series data analysis and will provide a platform for researchers and practitioners from academia and industry to discuss potential research directions and critical technical issues and present solutions to tackle related issues in practical applications. We will invite researchers and practitioners from the related areas of AI, machine learning, data science, statistics, and many others to contribute to this workshop. | Learning and mining from time series data | Algorithmic, theoretical, statistical, or systems-based developments |

